# üìò Documenta√ß√£o T√©cnica ‚Äì Normaliza√ß√£o e Tratamento de Dados com SQL + Databricks

## üßæ Vis√£o Geral

Este projeto teve como objetivo realizar a normaliza√ß√£o e tratamento de dados financeiros e transacionais utilizando a plataforma **Databricks**, integrando m√∫ltiplas fontes de dados e aplicando regras espec√≠ficas de neg√≥cio. O trabalho envolveu a leitura de arquivos CSV, cria√ß√£o de vis√µes tempor√°rias, jun√ß√µes entre bases, limpeza de dados e c√°lculo de comiss√µes.

---

## üîπ Etapas e Processos Realizados

### 1. **Leitura dos Arquivos de Entrada**
Os seguintes arquivos foram carregados no ambiente Databricks:

- `reporte_fd.csv`: cont√©m registros financeiros com n√∫mero da transa√ß√£o, valores, datas e n√∫meros de cart√£o.
- `parametria_comercio.csv`: cont√©m metadados sobre com√©rcios, como tipo e identificador.
- `db_dota.csv`: base principal com movimenta√ß√µes detalhadas, adquirentes, bandeiras, valores e datas.

Esses arquivos foram lidos com Spark e armazenados em `DataFrames`.

---

### 2. **Cria√ß√£o de Views Tempor√°rias**
Cada `DataFrame` foi convertido em uma **view tempor√°ria** para que pudesse ser manipulado usando comandos SQL dentro do Databricks.

Views criadas:
- `reporte_fd_view`
- `parametria_comercio_view`
- `db_dota_view`

---

### 3. **Transforma√ß√£o dos Dados da Base db_dota**

Foi criada a view `db_dota_view_transformation`, aplicando as seguintes transforma√ß√µes:

- **M√°scara do cart√£o**: concatena√ß√£o dos 6 primeiros e 4 √∫ltimos d√≠gitos, mascarando os intermedi√°rios com `XXXXXX`.
- **C√≥digo de autoriza√ß√£o**: substitui√ß√£o por `NULL` caso o valor seja `'000000'` e o adquirente seja `'Cabal'`.
- **Adquirente unificado**: convers√£o condicional para `'FD'`, `'PRISMA'` ou o valor em caixa alta.
- **Bandeira da transa√ß√£o**: normaliza√ß√£o dos nomes das bandeiras com base no `PAY_METHOD` ou prefixo do n√∫mero do cart√£o.
- **N√∫mero do com√©rcio**: consolida√ß√£o dos campos de adquir√™ncia para formar um identificador √∫nico.
- **Data de cria√ß√£o da movimenta√ß√£o**: adi√ß√£o de um dia √† data original e remo√ß√£o da hora.

---

### 4. **Filtragem por Tipo de Com√©rcio**
Foi realizada uma jun√ß√£o da base transformada `db_dota_view_transformation` com a `parametria_comercio_view`, filtrando apenas os com√©rcios do tipo `'ESTANDAR'`.

Resultado armazenado na view:
- `db_dota_view_transformation_and_comercio`

---

### 5. **Transforma√ß√µes na Base reporte_fd**

Na view `reporte_fd_view`, foram criadas duas novas colunas:

- `LIQ_6_TARJETA`: 6 primeiros d√≠gitos do n√∫mero do cart√£o
- `LIQ_4_TARJETA`: 4 √∫ltimos d√≠gitos do n√∫mero do cart√£o

Essas colunas foram usadas para facilitar a jun√ß√£o com a base `db_dota`.

---

### 6. **Jun√ß√£o das Bases e Cruzamento de Informa√ß√µes**

Criada a view `db_dota_with_reporte_fd_view`, unindo as informa√ß√µes de:

- `db_dota_view_transformation_and_comercio`
- `reporte_fd_view_transformation`

Crit√©rios de jun√ß√£o:
- N√∫mero do com√©rcio
- D√≠gitos do cart√£o (6 primeiros e 4 √∫ltimos)
- Data da movimenta√ß√£o (com 1 dia de diferen√ßa ajustado)
- Valor da transa√ß√£o

Essa jun√ß√£o permitiu consolidar os dados de transa√ß√µes entre os dois arquivos.

---

### 7. **C√°lculo de Total por Documento Coletor**

Criada a view `pivot_table` com o agrupamento por `PAY_COLLECTOR_DOCUMENT`, somando o campo `Importe`.

Objetivo: calcular o valor total transacionado por documento coletor.

---

### 8. **C√°lculo da Comiss√£o**

Aplicadas as regras de neg√≥cio para c√°lculo da comiss√£o:

- **< R$20.000**: comiss√£o = R$0
- **R$20.001 a R$40.000**: comiss√£o = 1% sobre o excedente + 1.21% do total
- **> R$40.000**: comiss√£o = 
  - 3% sobre o que exceder R$40.000
  - 1% sobre os valores entre R$20.001 e R$40.000
  - 1.21% sobre o total

Essa l√≥gica foi aplicada diretamente em SQL com `CASE WHEN`.

---

## üì§ Sa√≠das Geradas

- Base final com comiss√µes por documento
- Arquivo CSV com os dados j√° tratados
- Planilha Excel com as transforma√ß√µes e regras aplicadas

---

## üõ† Tecnologias Utilizadas

- üìç **Apache Spark**
- üìç **SQL + Python (PySpark)**
- üìç **Databricks**
- üìç **Arquivos CSV e Excel**

---

## üîó Notebook na Nuvem

[Acesse o notebook Databricks com c√≥digo completo e execu√ß√£o](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1186711081889598/3474049659358438/2401084538103174/latest.html)

---
